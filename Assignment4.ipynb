{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "\n",
    "Before working on this assignment please read these instructions fully. In the submission area, you will notice that you can click the link to **Preview the Grading** for each step of the assignment. This is the criteria that will be used for peer grading. Please familiarize yourself with the criteria before beginning the assignment.\n",
    "\n",
    "This assignment requires that you to find **at least** two datasets on the web which are related, and that you visualize these datasets to answer a question with the broad topic of **religious events or traditions** (see below) for the region of **Ann Arbor, Michigan, United States**, or **United States** more broadly.\n",
    "\n",
    "You can merge these datasets with data from different regions if you like! For instance, you might want to compare **Ann Arbor, Michigan, United States** to Ann Arbor, USA. In that case at least one source file must be about **Ann Arbor, Michigan, United States**.\n",
    "\n",
    "You are welcome to choose datasets at your discretion, but keep in mind **they will be shared with your peers**, so choose appropriate datasets. Sensitive, confidential, illicit, and proprietary materials are not good choices for datasets for this assignment. You are welcome to upload datasets of your own as well, and link to them using a third party repository such as github, bitbucket, pastebin, etc. Please be aware of the Coursera terms of service with respect to intellectual property.\n",
    "\n",
    "Also, you are welcome to preserve data in its original language, but for the purposes of grading you should provide english translations. You are welcome to provide multiple visuals in different languages if you would like!\n",
    "\n",
    "As this assignment is for the whole course, you must incorporate principles discussed in the first week, such as having as high data-ink ratio (Tufte) and aligning with Cairoâ€™s principles of truth, beauty, function, and insight.\n",
    "\n",
    "Here are the assignment instructions:\n",
    "\n",
    " * State the region and the domain category that your data sets are about (e.g., **Ann Arbor, Michigan, United States** and **religious events or traditions**).\n",
    " * You must state a question about the domain category and region that you identified as being interesting.\n",
    " * You must provide at least two links to available datasets. These could be links to files such as CSV or Excel files, or links to websites which might have data in tabular form, such as Wikipedia pages.\n",
    " * You must upload an image which addresses the research question you stated. In addition to addressing the question, this visual should follow Cairo's principles of truthfulness, functionality, beauty, and insightfulness.\n",
    " * You must contribute a short (1-2 paragraph) written justification of how your visualization addresses your stated research question.\n",
    "\n",
    "What do we mean by **religious events or traditions**?  For this category you might consider calendar events, demographic data about religion in the region and neighboring regions, participation in religious events, or how religious events relate to political events, social movements, or historical events.\n",
    "\n",
    "## Tips\n",
    "* Wikipedia is an excellent source of data, and I strongly encourage you to explore it for new data sources.\n",
    "* Many governments run open data initiatives at the city, region, and country levels, and these are wonderful resources for localized data sources.\n",
    "* Several international agencies, such as the [United Nations](http://data.un.org/), the [World Bank](http://data.worldbank.org/), the [Global Open Data Index](http://index.okfn.org/place/) are other great places to look for data.\n",
    "* This assignment requires you to convert and clean datafiles. Check out the discussion forums for tips on how to do this from various sources, and share your successes with your fellow students!\n",
    "\n",
    "## Example\n",
    "Looking for an example? Here's what our course assistant put together for the **Ann Arbor, MI, USA** area using **sports and athletics** as the topic. [Example Solution File](./readonly/Assignment4_example.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading https://files.pythonhosted.org/packages/83/c5/3cf9cdc39a6f2552922f79915f36b45a95b71fd343cfc51170a5b6ddb6e8/geopandas-0.7.0-py2.py3-none-any.whl (928kB)\n",
      "Collecting fiona (from geopandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/42/f4a7cac53b28fa70e9a93d0e89a24d33e14826dad6644b699362ad84dde0/Fiona-1.8.13.post1.tar.gz (1.2MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\gthampi\\Anaconda3\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\gthampi\\\\AppData\\\\Local\\\\Temp\\\\pip-install-49csi1vc\\\\fiona\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\gthampi\\\\AppData\\\\Local\\\\Temp\\\\pip-install-49csi1vc\\\\fiona\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base pip-egg-info\n",
      "         cwd: C:\\Users\\gthampi\\AppData\\Local\\Temp\\pip-install-49csi1vc\\fiona\\\n",
      "    Complete output (1 lines):\n",
      "    A GDAL API version must be specified. Provide a path to gdal-config using a GDAL_CONFIG environment variable or use a GDAL_VERSION environment variable.\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting descartes\n",
      "  Downloading https://files.pythonhosted.org/packages/e5/b6/1ed2eb03989ae574584664985367ba70cd9cf8b32ee8cad0e8aaeac819f3/descartes-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gthampi\\anaconda3\\lib\\site-packages (from descartes) (3.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gthampi\\anaconda3\\lib\\site-packages (from matplotlib->descartes) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gthampi\\anaconda3\\lib\\site-packages (from matplotlib->descartes) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\gthampi\\anaconda3\\lib\\site-packages (from matplotlib->descartes) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\gthampi\\anaconda3\\lib\\site-packages (from matplotlib->descartes) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\gthampi\\anaconda3\\lib\\site-packages (from matplotlib->descartes) (1.16.5)\n",
      "Requirement already satisfied: six in c:\\users\\gthampi\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->descartes) (1.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gthampi\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->descartes) (41.4.0)\n",
      "Installing collected packages: descartes\n",
      "Successfully installed descartes-1.1.0\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f802ca5246c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib notebook'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdescartes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmplleaflet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import geopandas\n",
    "import descartes\n",
    "import mplleaflet as lft\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "geopandas.datasets.available\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### create the figure with religiosity\n",
    "\n",
    "\n",
    "## read in shape file\n",
    "counties = geopandas.read_file('gz_2010_us_050_00_20m.shp')\n",
    "\n",
    "\n",
    "## I'm removing puerto rico and the westmost alaskan county as they severely skew the map\n",
    "counties = counties[counties['STATE']!='72']\n",
    "counties=counties[counties.bounds['maxx']!=max(counties.bounds['maxx'])]\n",
    "##create a FIPS code for merging\n",
    "counties['FIPS'] = counties['STATE'] + counties['COUNTY']\n",
    "counties['FIPS'] = counties['FIPS'].astype(int)\n",
    "\n",
    "## read in religiosity data\n",
    "religion = pd.read_excel('religion.xlsx')\n",
    "\n",
    "\n",
    "## merge with counties\n",
    "df = pd.merge(left=counties, right = religion, how = 'left',left_on = 'FIPS' , right_on = 'FIPS')\n",
    "\n",
    "## read in climate survey data\n",
    "climate = pd.read_csv('climate.csv', encoding = 'utf-8')\n",
    "\n",
    "##only retain county level data\n",
    "climate = climate[climate['GeoType']=='County']\n",
    "climate['State']=climate['GeoName'].str.extract(r'(, )(.*)')[1]\n",
    "#map state to two letter state\n",
    "stateac=pd.read_csv('state acronym.csv', encoding = 'utf-8')\n",
    "stateac['State'] = stateac['State'].str.strip()\n",
    "\n",
    "climate=pd.merge(left=climate, right = stateac, how='left' , left_on = 'State', right_on = 'State', indicator = True)\n",
    "\n",
    "## do some regex to clean up the county names, this specially needed because this file doesn't have fips codes\n",
    "climate['GeoName'].replace( r',.*' , r'', regex = True, inplace = True)\n",
    "climate['GeoName'].replace( r' County' , r'', regex = True, inplace = True)\n",
    "climate['GeoName'].replace( r' Parish' , r'', regex = True, inplace = True)\n",
    "climate['GeoName'].replace( r' Borough' , r'', regex = True, inplace = True)\n",
    "climate['GeoName'].replace( r' Census Area' , r'', regex = True, inplace = True)\n",
    "climate['GeoName'].replace( r' Municipality' , r'', regex = True, inplace = True)\n",
    "\n",
    "climate['StateCounty'] = climate['GeoName'].str.strip() + climate['Acronym'].str.strip()\n",
    "\n",
    "## fips code\n",
    "fips = pd.read_csv('fips.csv', encoding = 'utf-8')\n",
    "fips['StateCounty'] = fips['Name'].str.strip() + fips['State'].str.strip()\n",
    "\n",
    "\n",
    "#merge climate and fips\n",
    "\n",
    "climate = pd.merge(left = climate, right = fips, how = 'left' , left_on = 'StateCounty' , right_on = 'StateCounty')\n",
    "\n",
    "#merge climate file to the county file\n",
    "df = pd.merge(left=df, right = climate, how = 'left',left_on = 'FIPS' , right_on = 'FIPS')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "## create plot grid\n",
    "fig = plt.figure(figsize =(10,10))\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax4 = fig.add_subplot(2,2,4)\n",
    "ax3 = fig.add_subplot(2,2,3)\n",
    "\n",
    "\n",
    "\n",
    "#draw first plot\n",
    "df.plot(ax=ax1,cmap = 'Blues',  column = 'prienvOppose')\n",
    "## insert its colorbar, the default colorbar is ugly and the plot function doesn't support modifying it, below work around was necessary\n",
    "\n",
    "mn = df.prienvOppose.min()\n",
    "mx = df.prienvOppose.max()\n",
    "norm = Normalize(vmin=mn, vmax=mx)\n",
    "n_cmap = cm.ScalarMappable(norm=norm, cmap=\"Blues\")\n",
    "## someone tell me why the below is necessary! \n",
    "n_cmap.set_array([])\n",
    "cbar1=ax1.get_figure().colorbar(n_cmap, ax=ax1, orientation='horizontal', format = \"%d\" , shrink =  0.75)\n",
    "ax1.set_title('County population, in percentage \\n who oppose prioritizing the environment over the economy', fontdict = {'fontsize' : 8}, color = 'darkblue')\n",
    "cbar1.ax.tick_params( width=0, labelsize =7)\n",
    "\n",
    "\n",
    "## draw plot 4  \n",
    "df.plot(ax=ax4, cmap = 'Reds' , column = 'EVANRATE')\n",
    "mn = df.EVANRATE.min()\n",
    "mx = df.EVANRATE.max()\n",
    "norm = Normalize(vmin=mn, vmax=mx)\n",
    "n_cmap = cm.ScalarMappable(norm=norm, cmap=\"Reds\")\n",
    "## someone tell me why the below is necessary! \n",
    "n_cmap.set_array([])\n",
    "cbar=ax4.get_figure().colorbar(n_cmap, ax=ax4, orientation='horizontal', format = \"%d\", shrink = 0.75 )\n",
    "ax4.set_title('County population, per thousand \\n who are adherents of evangelical christianity', fontdict = {'fontsize' : 8}, color = 'darkred')\n",
    "ax4.tick_params(axis='both', which='both', length=0)\n",
    "cbar.ax.tick_params( width=0, labelsize=7)\n",
    "\n",
    "## draw the scatter plot\n",
    "ax2.scatter(x=df['EVANRATE'], y=df['prienvOppose'] , s =2, color = 'darkgrey' )\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.yaxis.set_major_formatter(mtick.FormatStrFormatter('%d'))\n",
    "ax2.set_title('Evangelical christianity adherents per thousand vs \\n percentage opposed to prioritizing the environment, US counties' , fontdict = {'fontsize' : 8}, color = 'black')\n",
    "ax2.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "##give the figure a title\n",
    "fig.suptitle('A visual of religious belief vs attitude towards the environment \\n across counties in the United States', fontsize=16)\n",
    "\n",
    "\n",
    "ax1.set_axis_off()\n",
    "ax3.set_axis_off()\n",
    "ax4.set_axis_off()\n",
    "plt.savefig('religion v environment.png', facecolor= 'white')\n",
    "plt.show()                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
